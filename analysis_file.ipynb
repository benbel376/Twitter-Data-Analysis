{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a856c61",
   "metadata": {},
   "source": [
    "# Twitter Data Analysis and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c739b1",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ebe324",
   "metadata": {},
   "source": [
    "importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fb72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe72606",
   "metadata": {},
   "source": [
    "importnig processing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4c8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_dataframe import read_json         # a function to load json_data \n",
    "from extract_dataframe import TweetDfExtractor  # and a class to extract relevant variables.    \n",
    "from clean_tweets_dataframe import Clean_Tweets        # collection of functions to for cleaning the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b9935",
   "metadata": {},
   "source": [
    "Loading JSON file, selecting relevant variables, and generating a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tweet_list = read_json(\"data/Economic_Twitter_Data.json\")\n",
    "tweet = TweetDfExtractor(tweet_list)\n",
    "tweet.get_tweet_df(True)  # this will also generate a CSV file.\n",
    "print(\"Please, load the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6b174",
   "metadata": {},
   "source": [
    "Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea21d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('processed_tweet_data.csv')  # loads the csv file created above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f528c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc8728",
   "metadata": {},
   "source": [
    "Running common data cleaning operations from the Clean_Tweets class...!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50915cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Clean_Tweets(tweet_df)\n",
    "tweet_df = cleaner.drop_unwanted_column(tweet_df)\n",
    "tweet_df = cleaner.drop_duplicate(tweet_df)\n",
    "tweet_df = cleaner.convert_to_datetime(tweet_df)\n",
    "tweet_df = cleaner.convert_to_numbers(tweet_df)\n",
    "clean_tweet_df = cleaner.remove_non_english_tweets(tweet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8247232",
   "metadata": {},
   "source": [
    "## Data Exploration and Reorganization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.shape   # checking the number of columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.info()  # checking available columns, their datatypes and Null count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.nunique() # checks unique values in each columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab342e",
   "metadata": {},
   "source": [
    "<h3>Observation:</h3>\n",
    "    <li> There are a total of 16374 obsrvations and 17 variables </li>\n",
    "    <li> There are 464 unique users</li>\n",
    "    <li> There are 220 unique locations.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761534c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.head()  #checking the top 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.describe()   # summarizing numerical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4c641",
   "metadata": {},
   "source": [
    "<h3>Observation:</h3>\n",
    "    <li>75% of polarity values are below or equal to 0.2, which suggests negative polarity</li>\n",
    "    <li>75% of subjectivity values are below or equal to 0.5, which suggests prevalence of opinions rather than facts</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f1add",
   "metadata": {},
   "source": [
    "selection and reorganization of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce111fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the relevant variables for further analysis\n",
    "sho_tweet_df = clean_tweet_df.drop(['original_text', 'source', 'user_mentions', 'possibly_sensitive'], axis=1)\n",
    "loc_tweet_df = sho_tweet_df.dropna() # droping rows with null values\n",
    "\n",
    "#resetting indexes\n",
    "sho_tweet_df = sho_tweet_df.reset_index();\n",
    "sho_tweet_df = sho_tweet_df.drop(columns=['index'])\n",
    "\n",
    "loc_tweet_df = loc_tweet_df.reset_index();\n",
    "loc_tweet_df = loc_tweet_df.drop(columns=['index'])\n",
    "\n",
    "print(clean_tweet_df.shape)\n",
    "print(sho_tweet_df.shape)\n",
    "print(loc_tweet_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296cea0e",
   "metadata": {},
   "source": [
    "creating a new variable: sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_group (p): \n",
    "    if p > 0:\n",
    "        return 'positive'\n",
    "    elif p < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.Series([sentiment_group(row_val) for row_val in list(loc_tweet_df['polarity'])])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa931ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sho_tweet_df = pd.concat([sho_tweet_df, sentiment.rename(\"sentiment\")], axis=1)\n",
    "loc_tweet_df = pd.concat([loc_tweet_df, sentiment.rename(\"sentiment\")], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ea042",
   "metadata": {},
   "source": [
    "## Analysis and Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b02628",
   "metadata": {},
   "source": [
    "### Location based explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b142eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading countries basic information module and extracting african countries\n",
    "from countries_info import countries\n",
    "african_countries = []\n",
    "for item in countries:\n",
    "    if item['continent'] == 'Africa':\n",
    "        african_countries.append(item['name'])\n",
    "        african_countries.append(item['capital'])\n",
    "    \n",
    "\n",
    "# extracting countries from africa \n",
    "ava_countries = {}\n",
    "for item in clean_tweet_df.location:\n",
    "    if item in african_countries:\n",
    "        if item not in ava_countries:\n",
    "            ava_countries[item] = 1\n",
    "        else:\n",
    "            ava_countries[item] = ava_countries[item]+1\n",
    "\n",
    "print(\"\\ntweet_count summary by african countries\\n\")\n",
    "# the count of tweets in association with each african countries.            \n",
    "afr_df = pd.DataFrame ({ 'places': ava_countries.keys(), 'tweet_count': ava_countries.values()})\n",
    "afr_df.sort_values(by=['tweet_count'], inplace=True, ascending = False)\n",
    "afr_df['percentage'] = ((afr_df['tweet_count']/loc_tweet_df.shape[0])*100).round(1)\n",
    "print(\"\\n\",afr_df, \"\\n\")\n",
    "\n",
    "# the tweet dataframe filtered by african countries\n",
    "afr_list = list(ava_countries.keys())\n",
    "afr_tweets_df = loc_tweet_df[loc_tweet_df['location'].isin(afr_list)]\n",
    "\n",
    "print(\"tweet count summary by top 10 global countries\\n\")\n",
    "\n",
    "top_loc = loc_tweet_df.groupby(['location']).size().sort_values(ascending=False).to_frame().reset_index().head(10)\n",
    "top_loc.columns = ['places', 'tweet_count']\n",
    "top_loc['percentage'] = ((top_loc['tweet_count']/loc_tweet_df.shape[0])*100).round(1)\n",
    "\n",
    "print(top_loc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe1c8d",
   "metadata": {},
   "source": [
    "<h3>Observations:</h3>\n",
    "    <li> The majority of tweets are not associated with locations</li> \n",
    "    <li> Only four african countries were associated with some tweets: Kenya, South Africa, Namibia, Mauritius</li>\n",
    "    <li> In general India is the most mentioned location, by about 3.1% of the total tweets</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(top_loc['places'])\n",
    "values = list(top_loc['tweet_count'])\n",
    "\n",
    "fig = plt.figure(figsize = (15, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(labels, values, color ='purple',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Locations\")\n",
    "plt.ylabel(\"Tweet Count\")\n",
    "plt.title(\"Tweets associated with locations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4d0a2",
   "metadata": {},
   "source": [
    "exploring the sentiment in africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_afr = afr_tweets_df.groupby(['location', 'sentiment']).size().to_frame().reset_index()\n",
    "gr_afr.columns=['location','sentiment', 'count']\n",
    "print(gr_afr)\n",
    "# grouping by country and sentiment\n",
    "#afr_tweets_df.groupby(['location', 'sentiment']).size().groupby(level=1).max() # grouping by country and sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0d229",
   "metadata": {},
   "source": [
    "<h3>Observations:</h3>\n",
    "    <li> The majority of tweets associated with african locations have neutral sentiment</li> \n",
    "    <li> tweets associated with sourth africa have the largest number of negative sentiment tweets</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e99d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering dataframe by top locations\n",
    "top_loc_list = list(top_loc['places'])\n",
    "top_loc_tweets_df = loc_tweet_df[loc_tweet_df['location'].isin(top_loc_list)]\n",
    "\n",
    "#grouping by top locations and sentiment\n",
    "gr_all = top_loc_tweets_df.groupby(['location', 'sentiment']).size().to_frame().reset_index()\n",
    "gr_all.columns=['location','sentiment', 'count']\n",
    "print(gr_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb4ec1",
   "metadata": {},
   "source": [
    "<h3>Observations:</h3>\n",
    "    <li> The majority of tweets associated with locations have neutral or positive sentiment</li> \n",
    "    <li> tweets associated with canada have relatively the largest number of negative sentiment tweets followed by India</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d049f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "positive = len(sho_tweet_df[sho_tweet_df['sentiment'] == \"positive\"])\n",
    "negative = len(sho_tweet_df[sho_tweet_df['sentiment'] == \"negative\"])\n",
    "neutral = len(sho_tweet_df[sho_tweet_df['sentiment'] == \"neutral\"])\n",
    "\n",
    "labels = ['neutral', 'positive', 'negative']\n",
    "values = [negative, positive, neutral]\n",
    "\n",
    "fig = plt.figure(figsize = (15, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(labels, values, color ='orange',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Tweet Count\")\n",
    "plt.title(\"Tweets associated with Sentiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc85a6b",
   "metadata": {},
   "source": [
    "<h3>Observations:</h3>\n",
    "    <li> in general, negative sentiments are dominanat</li> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sho_tweet_df.groupby('sentiment')['clean_text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baba51b",
   "metadata": {},
   "source": [
    "### Hashtag based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hastags one by one\n",
    "hashtags_list_df = sho_tweet_df.loc[sho_tweet_df.hashtags.apply(lambda hashtags_list: hashtags_list !=[]),['hashtags']]\n",
    "hashtags_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d95b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #create dataframe where each use of hashtag gets its own row\n",
    "flattened_hashtags_df = pd.DataFrame(\n",
    "    [hashtag for hashtags_list in hashtags_list_df.hashtags\n",
    "    for hashtag in hashtags_list],\n",
    "    columns=['hashtag'])\n",
    "\n",
    "flattened_hashtags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f288c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add flatten_hashtags to tweet_df\n",
    "sho_tweet_df[\"flattened_hashtags\"]= flattened_hashtags_df\n",
    "sho_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ee792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Top 30 Hashtags\n",
    "sho_tweet_df['flattened_hashtags'].value_counts()[:30].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b0a37",
   "metadata": {},
   "source": [
    "## Sentiment analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sho_tweet_df['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sho_tweet_df = sho_tweet_df.drop(sho_tweet_df[sho_tweet_df.sentiment == 'neutral'].index)\n",
    "sho_tweet_df = sho_tweet_df.reset_index();\n",
    "sho_tweet_df = sho_tweet_df.drop(columns=['index'])\n",
    "sho_tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueArray = pd.Series([1 if row_val == 'positive' else 0 for row_val in sho_tweet_df['sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba73e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sho_tweet_df['valueArray'] = valueArray\n",
    "sho_tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sho_tweet_df['clean_text']\n",
    "y = sho_tweet_df['valueArray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.size)\n",
    "print(X_test.size)\n",
    "print(y_train.size)\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train = X_train.replace(np.nan, '', regex=True)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts = X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=9000, tol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.replace(np.nan, '', regex=True)\n",
    "# use transform not fit_transform\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_counts = X_test_counts.toarray()\n",
    "# prediction = clf.prevaluedict(X_test_counts)\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f36e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
