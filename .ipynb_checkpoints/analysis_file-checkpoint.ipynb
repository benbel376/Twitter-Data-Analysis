{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a856c61",
   "metadata": {},
   "source": [
    "# Twitter Data Analysis and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185564ab",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ebe324",
   "metadata": {},
   "source": [
    "importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fb72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe72606",
   "metadata": {},
   "source": [
    "importnig processing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4c8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_dataframe import read_json         # a function to load json_data \n",
    "from extract_dataframe import TweetDfExtractor  # and a class to extract relevant variables.    \n",
    "from clean_tweets_dataframe import Clean_Tweets        # collection of functions to for cleaning the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b9935",
   "metadata": {},
   "source": [
    "Loading JSON file, selecting relevant variables, and generating a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51d517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Successfully Saved.!!!\n",
      "Please, load the CSV file\n"
     ]
    }
   ],
   "source": [
    "_, tweet_list = read_json(\"data/Economic_Twitter_Data.json\")\n",
    "tweet = TweetDfExtractor(tweet_list)\n",
    "tweet.get_tweet_df(True)  # this will also generate a CSV file.\n",
    "print(\"Please, load the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bc253",
   "metadata": {},
   "source": [
    "Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea21d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('processed_tweet_data.csv')  # loads the csv file created above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f528c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c4545",
   "metadata": {},
   "source": [
    "Running the data cleaning methods from the Clean_Tweets class...!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50915cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning in Action...!!!\n",
      "Unwanted_columns successfully removed\n",
      "Duplicate rows successfully removed\n",
      "Strings successfully converted to datetime object\n",
      "Strings successfully converted to numeric object\n",
      "Non-English languages succesfully removed\n"
     ]
    }
   ],
   "source": [
    "cleaner = Clean_Tweets(tweet_df)\n",
    "tweet_df = cleaner.drop_unwanted_column(tweet_df)\n",
    "tweet_df = cleaner.drop_duplicate(tweet_df)\n",
    "tweet_df = cleaner.convert_to_datetime(tweet_df)\n",
    "tweet_df = cleaner.convert_to_numbers(tweet_df)\n",
    "clean_tweet_df = cleaner.remove_non_english_tweets(tweet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8247232",
   "metadata": {},
   "source": [
    "## Data Exploration and Reorganization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6476923d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16374, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet_df.shape   # checking the number of columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5d251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16374 entries, 38 to 24622\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   created_at          16374 non-null  datetime64[ns, UTC]\n",
      " 1   source              16374 non-null  object             \n",
      " 2   original_text       16374 non-null  object             \n",
      " 3   clean_text          16371 non-null  object             \n",
      " 4   polarity            16374 non-null  float64            \n",
      " 5   subjectivity        16374 non-null  float64            \n",
      " 6   screen_name         16374 non-null  object             \n",
      " 7   language            16374 non-null  object             \n",
      " 8   retweet_count       16374 non-null  int64              \n",
      " 9   friends_count       16374 non-null  int64              \n",
      " 10  hashtags            16374 non-null  object             \n",
      " 11  statuses            16374 non-null  int64              \n",
      " 12  followers_count     16374 non-null  int64              \n",
      " 13  user_mentions       16374 non-null  object             \n",
      " 14  possibly_sensitive  6168 non-null   object             \n",
      " 15  favourites_count    16374 non-null  int64              \n",
      " 16  location            10671 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(5), object(9)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_tweet_df.info()  # checking available columns, their datatypes and Null count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53fee3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at            15675\n",
       "source                   53\n",
       "original_text         15082\n",
       "clean_text            15022\n",
       "polarity               1047\n",
       "subjectivity            877\n",
       "screen_name             464\n",
       "language                  1\n",
       "retweet_count          1718\n",
       "friends_count           394\n",
       "hashtags               4293\n",
       "statuses                458\n",
       "followers_count         426\n",
       "user_mentions          7939\n",
       "possibly_sensitive        2\n",
       "favourites_count        458\n",
       "location                220\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet_df.nunique() # checks unique values in each columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28c431",
   "metadata": {},
   "source": [
    "Insights:<br>\n",
    "    <li> There are 464 unique users</li>\n",
    "    <li> There are 220 unique locations.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761534c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>language</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>statuses</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-04-22 22:17:05+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @NorthstarCharts: The 10-year yield is tell...</td>\n",
       "      <td>The 10-year yield is telling us that there's ...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>davideiacovozzi</td>\n",
       "      <td>en</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>[{'text': 'gold', 'indices': [116, 121]}, {'te...</td>\n",
       "      <td>281</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'screen_name': 'NorthstarCharts', 'name': 'N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-04-22 13:44:53+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @MichaelAArouet: German 10y mortgage rate w...</td>\n",
       "      <td>…</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>davideiacovozzi</td>\n",
       "      <td>en</td>\n",
       "      <td>32</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>281</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'screen_name': 'MichaelAArouet', 'name': 'Mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-04-22 06:10:34+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @goldseek: When? https://t.co/kO2FfHKaZg</td>\n",
       "      <td>//t.co/kO2FfHKaZg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>davideiacovozzi</td>\n",
       "      <td>en</td>\n",
       "      <td>26</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>281</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'screen_name': 'goldseek', 'name': 'Peter ⚒ ...</td>\n",
       "      <td>False</td>\n",
       "      <td>12179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-04-21 17:22:09+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @charliebilello: The 30-year mortgage rate ...</td>\n",
       "      <td>The 30-year mortgage rate in the US rises to ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>davideiacovozzi</td>\n",
       "      <td>en</td>\n",
       "      <td>213</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>281</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'screen_name': 'charliebilello', 'name': 'Ch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-04-21 10:32:26+00:00</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @biancoresearch: Rates rise until something...</td>\n",
       "      <td>//t.co/brNJeK3WTb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>davideiacovozzi</td>\n",
       "      <td>en</td>\n",
       "      <td>417</td>\n",
       "      <td>55</td>\n",
       "      <td>[]</td>\n",
       "      <td>281</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'screen_name': 'biancoresearch', 'name': 'Ji...</td>\n",
       "      <td>False</td>\n",
       "      <td>12179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "38 2022-04-22 22:17:05+00:00   \n",
       "39 2022-04-22 13:44:53+00:00   \n",
       "41 2022-04-22 06:10:34+00:00   \n",
       "42 2022-04-21 17:22:09+00:00   \n",
       "43 2022-04-21 10:32:26+00:00   \n",
       "\n",
       "                                               source  \\\n",
       "38  <a href=\"http://twitter.com/download/android\" ...   \n",
       "39  <a href=\"http://twitter.com/download/android\" ...   \n",
       "41  <a href=\"http://twitter.com/download/android\" ...   \n",
       "42  <a href=\"http://twitter.com/download/android\" ...   \n",
       "43  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                        original_text  \\\n",
       "38  RT @NorthstarCharts: The 10-year yield is tell...   \n",
       "39  RT @MichaelAArouet: German 10y mortgage rate w...   \n",
       "41        RT @goldseek: When? https://t.co/kO2FfHKaZg   \n",
       "42  RT @charliebilello: The 30-year mortgage rate ...   \n",
       "43  RT @biancoresearch: Rates rise until something...   \n",
       "\n",
       "                                           clean_text  polarity  subjectivity  \\\n",
       "38   The 10-year yield is telling us that there's ...      0.16      0.540000   \n",
       "39                                                  …      0.00      0.000000   \n",
       "41                                  //t.co/kO2FfHKaZg      0.00      0.000000   \n",
       "42   The 30-year mortgage rate in the US rises to ...      0.00      0.183333   \n",
       "43                                  //t.co/brNJeK3WTb      0.00      0.000000   \n",
       "\n",
       "        screen_name language  retweet_count  friends_count  \\\n",
       "38  davideiacovozzi       en             43             55   \n",
       "39  davideiacovozzi       en             32             55   \n",
       "41  davideiacovozzi       en             26             55   \n",
       "42  davideiacovozzi       en            213             55   \n",
       "43  davideiacovozzi       en            417             55   \n",
       "\n",
       "                                             hashtags  statuses  \\\n",
       "38  [{'text': 'gold', 'indices': [116, 121]}, {'te...       281   \n",
       "39                                                 []       281   \n",
       "41                                                 []       281   \n",
       "42                                                 []       281   \n",
       "43                                                 []       281   \n",
       "\n",
       "    followers_count                                      user_mentions  \\\n",
       "38               18  [{'screen_name': 'NorthstarCharts', 'name': 'N...   \n",
       "39               18  [{'screen_name': 'MichaelAArouet', 'name': 'Mi...   \n",
       "41               18  [{'screen_name': 'goldseek', 'name': 'Peter ⚒ ...   \n",
       "42               18  [{'screen_name': 'charliebilello', 'name': 'Ch...   \n",
       "43               18  [{'screen_name': 'biancoresearch', 'name': 'Ji...   \n",
       "\n",
       "   possibly_sensitive  favourites_count location  \n",
       "38                NaN             12179      NaN  \n",
       "39                NaN             12179      NaN  \n",
       "41              False             12179      NaN  \n",
       "42                NaN             12179      NaN  \n",
       "43              False             12179      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet_df.head()  #checking the top 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83140ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>favourites_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16374.000000</td>\n",
       "      <td>16374.000000</td>\n",
       "      <td>16374.000000</td>\n",
       "      <td>16374.000000</td>\n",
       "      <td>1.637400e+04</td>\n",
       "      <td>1.637400e+04</td>\n",
       "      <td>16374.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.083105</td>\n",
       "      <td>0.295141</td>\n",
       "      <td>627.341151</td>\n",
       "      <td>1337.912056</td>\n",
       "      <td>4.503068e+04</td>\n",
       "      <td>5.359397e+04</td>\n",
       "      <td>22503.216563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.271508</td>\n",
       "      <td>0.314911</td>\n",
       "      <td>7104.387606</td>\n",
       "      <td>2975.315626</td>\n",
       "      <td>1.473958e+05</td>\n",
       "      <td>4.328630e+05</td>\n",
       "      <td>49450.473604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.610000e+03</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>542.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>7.322000e+03</td>\n",
       "      <td>5.430000e+02</td>\n",
       "      <td>4295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1433.000000</td>\n",
       "      <td>3.159900e+04</td>\n",
       "      <td>2.131000e+03</td>\n",
       "      <td>20269.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>434379.000000</td>\n",
       "      <td>41866.000000</td>\n",
       "      <td>2.307455e+06</td>\n",
       "      <td>6.027402e+06</td>\n",
       "      <td>529419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           polarity  subjectivity  retweet_count  friends_count      statuses  \\\n",
       "count  16374.000000  16374.000000   16374.000000   16374.000000  1.637400e+04   \n",
       "mean       0.083105      0.295141     627.341151    1337.912056  4.503068e+04   \n",
       "std        0.271508      0.314911    7104.387606    2975.315626  1.473958e+05   \n",
       "min       -1.000000      0.000000       0.000000       0.000000  1.000000e+00   \n",
       "25%        0.000000      0.000000       0.000000     113.000000  1.610000e+03   \n",
       "50%        0.000000      0.233333       2.000000     437.000000  7.322000e+03   \n",
       "75%        0.200000      0.500000      34.000000    1433.000000  3.159900e+04   \n",
       "max        1.000000      1.000000  434379.000000   41866.000000  2.307455e+06   \n",
       "\n",
       "       followers_count  favourites_count  \n",
       "count     1.637400e+04      16374.000000  \n",
       "mean      5.359397e+04      22503.216563  \n",
       "std       4.328630e+05      49450.473604  \n",
       "min       0.000000e+00          0.000000  \n",
       "25%       1.120000e+02        542.000000  \n",
       "50%       5.430000e+02       4295.000000  \n",
       "75%       2.131000e+03      20269.000000  \n",
       "max       6.027402e+06     529419.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet_df.describe()   # summarizing numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a836de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa0c852a",
   "metadata": {},
   "source": [
    "selection and reorganization of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce111fa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['original_text', 'source', 'user_mentions', 'possibly_sensitive'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# selecting only the relevant variables for further analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clean_tweet_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_tweet_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_mentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpossibly_sensitive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m clean_tweet_df \u001b[38;5;241m=\u001b[39m clean_tweet_df\u001b[38;5;241m.\u001b[39mdropna() \u001b[38;5;66;03m# droping rows with null values\u001b[39;00m\n\u001b[0;32m      4\u001b[0m clean_tweet_df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['original_text', 'source', 'user_mentions', 'possibly_sensitive'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# selecting only the relevant variables for further analysis\n",
    "clean_tweet_df = clean_tweet_df.drop(['original_text', 'source', 'user_mentions', 'possibly_sensitive'], axis=1)\n",
    "clean_tweet_df = clean_tweet_df.dropna() # droping rows with null values\n",
    "clean_tweet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296cea0e",
   "metadata": {},
   "source": [
    "creating a new variable: sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54f8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_group (p): # a function used to represent polarity values in string\n",
    "  if p > 0:\n",
    "    return 'positive'\n",
    "  elif p < 0:\n",
    "    return 'negative'\n",
    "  else:\n",
    "    return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4f5b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.Series([sentiment_group(row_val) for row_val in clean_tweet_df['polarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa931ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df = pd.concat([clean_tweet_df, sentiment.rename(\"sentiment\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ea042",
   "metadata": {},
   "source": [
    "### Analysis and Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d1ec2",
   "metadata": {},
   "source": [
    "Location based explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d15c6eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       countries  tweet_count  percentage\n",
      "2         Kenya          133         0.6\n",
      "0  South Africa           93         0.4\n",
      "1       Namibia           41         0.2\n",
      "3     Mauritius           25         0.1 \n",
      "\n",
      "dataframe filtered by african countries\n",
      "\n",
      "         countries  tweet_count  percentage\n",
      "0            India          519         2.4\n",
      "1    United States          254         1.2\n",
      "2        Sri Lanka          228         1.0\n",
      "3  London, England          195         0.9\n",
      "4           Canada          193         0.9\n",
      "5        New Delhi          172         0.8\n",
      "6           Mumbai          144         0.7\n",
      "7             Mars          143         0.7\n",
      "8            Kenya          133         0.6\n",
      "9   Chennai, India          113         0.5\n"
     ]
    }
   ],
   "source": [
    "# loading countries basic information module and extracting african countries\n",
    "from countries_info import countries\n",
    "african_countries = []\n",
    "for item in countries:\n",
    "    if item['continent'] == 'Africa':\n",
    "        african_countries.append(item['name'])\n",
    "        african_countries.append(item['capital'])\n",
    "    \n",
    "\n",
    "# extracting countries from africa \n",
    "ava_countries = {}\n",
    "for item in clean_tweet_df.location:\n",
    "    if item in african_countries:\n",
    "        if item not in ava_countries:\n",
    "            ava_countries[item] = 1\n",
    "        else:\n",
    "            ava_countries[item] = ava_countries[item]+1\n",
    "\n",
    "# the count of tweets in association with each african countries.            \n",
    "afr_df = pd.DataFrame ({ 'countries': ava_countries.keys(), 'tweet_count': ava_countries.values()})\n",
    "afr_df.sort_values(by=['tweet_count'], inplace=True, ascending = False)\n",
    "afr_df['percentage'] = ((afr_df['tweet_count']/clean_tweet_df.shape[0])*100).round(1)\n",
    "print(\"\\n\",afr_df, \"\\n\")\n",
    "\n",
    "# the tweet dataframe filtered by african countries\n",
    "afr_list = list(ava_countries.keys())\n",
    "afr_tweets_df = clean_tweet_df[clean_tweet_df['location'].isin(afr_list)]\n",
    "\n",
    "print(\"tweet count summary by location\")\n",
    "\n",
    "top_loc = clean_tweet_df.groupby(['location']).size().sort_values(ascending=False).to_frame().reset_index().head(10)\n",
    "top_loc.columns = ['countries', 'tweet_count']\n",
    "top_loc['percentage'] = ((top_loc['tweet_count']/clean_tweet_df.shape[0])*100).round(1)\n",
    "\n",
    "print(top_loc)\n",
    "#top_locations.plot(kind=\"pie\", subplots=True, title=\"Top 5 locations of users\");\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec7cb6",
   "metadata": {},
   "source": [
    "exploring the sentiment in africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.groupby(['location', 'sentiment']).size() # grouping by country and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d049f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['neutral', 'positive', 'negative']\n",
    "positive = len(clean_tweet_df[clean_tweet_df['sentiment'] == \"positive\"])\n",
    "negative = len(clean_tweet_df[clean_tweet_df['sentiment'] == \"negative\"])\n",
    "neutral = len(clean_tweet_df[clean_tweet_df['sentiment'] == \"neutral\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10,4))\n",
    "\n",
    "ax.bar(x=labels, height=[negative, positive, neutral], color='blue')\n",
    "ax.set_title('Barchart of sentiment column')\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "\n",
    "fig.suptitle('sentiment column plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f4a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.groupby('sentiment')['original_text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b0a37",
   "metadata": {},
   "source": [
    "## Sentiment analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_tweet_df['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df = clean_tweet_df.drop(clean_tweet_df[clean_tweet_df.sentiment == 'neutral'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0140dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valueArray = pd.Series([1 if row_val == 'positive' else 0 for row_val in clean_tweet_df['sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba73e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df['valueArray'] = valueArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_tweet_df['original_text']\n",
    "y = clean_tweet_df['valueArray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.size)\n",
    "print(X_test.size)\n",
    "print(y_train.size)\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train = X_train.replace(np.nan, '', regex=True)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts = X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=9000, tol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc898deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.replace(np.nan, '', regex=True)\n",
    "# use transform not fit_transform\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_counts = X_test_counts.toarray()\n",
    "# prediction = clf.prevaluedict(X_test_counts)\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f36e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
